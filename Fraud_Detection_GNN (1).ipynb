{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a203d14c-7c79-48e4-ba5d-83f865bd21fd",
   "metadata": {},
   "source": [
    "# Fraud Detection using Graph Neural Networks (GNN)\n",
    "\n",
    "This notebook implements an end-to-end **Fraud Detection** pipeline using **Graph Neural Networks**.\n",
    "\n",
    "Contents:\n",
    "- Synthetic graph dataset creation (users, devices, transactions, merchants)\n",
    "- Graph construction and conversion to PyTorch Geometric Data\n",
    "- GNN model (GraphSAGE / GAT) implementation and training\n",
    "- Evaluation (ROC AUC, Precision@K)\n",
    "- Visualizations and saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed471178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n",
      "'true' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas numpy scikit-learn torch torchvision torchaudio\n",
    "!pip install -q torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-<YOUR_TORCH_VERSION>.html || true\n",
    "!pip install -q scikit-learn matplotlib networkx pyvis joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365c96f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Data\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd646a0e",
   "metadata": {},
   "source": [
    "## 1) Create a synthetic heterogeneous graph\n",
    "We'll simulate a small graph containing Users, Devices, Transactions, and Merchants. Fraud labels will be assigned to some transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748035b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_graph(num_users=500, num_devices=300, num_merchants=100, num_transactions=2000, fraud_ratio=0.05, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    users = [f'U{i}' for i in range(num_users)]\n",
    "    devices = [f'D{i}' for i in range(num_devices)]\n",
    "    merchants = [f'M{i}' for i in range(num_merchants)]\n",
    "    \n",
    "    # Create transactions linking user->device->transaction->merchant\n",
    "    transactions = []\n",
    "    tx_rows = []\n",
    "    for t in range(num_transactions):\n",
    "        user = random.choice(users)\n",
    "        device = random.choice(devices)\n",
    "        merchant = random.choice(merchants)\n",
    "        amount = round(float(np.random.exponential(scale=50.0)), 2)\n",
    "        time = np.random.randint(1_600_000_000, 1_700_000_000)\n",
    "        transactions.append(f'T{t}')\n",
    "        tx_rows.append({'tx_id': f'T{t}', 'user': user, 'device': device, 'merchant': merchant, 'amount': amount, 'time': time})\n",
    "    \n",
    "    tx_df = pd.DataFrame(tx_rows)\n",
    "    # assign fraud labels randomly according to fraud_ratio, but inject patterns: some devices and merchants more likely fraud\n",
    "    tx_df['label'] = 0\n",
    "    # choose suspicious devices and merchants\n",
    "    suspicious_devices = set(np.random.choice(devices, size=max(1,int(0.02*len(devices))), replace=False))\n",
    "    suspicious_merchants = set(np.random.choice(merchants, size=max(1,int(0.02*len(merchants))), replace=False))\n",
    "    for idx, row in tx_df.sample(frac=fraud_ratio, random_state=seed).iterrows():\n",
    "        tx_df.at[idx,'label'] = 1\n",
    "    # increase fraud for suspicious device/merchant transactions\n",
    "    for idx, row in tx_df.iterrows():\n",
    "        if row['device'] in suspicious_devices and np.random.rand() < 0.3:\n",
    "            tx_df.at[idx,'label'] = 1\n",
    "        if row['merchant'] in suspicious_merchants and np.random.rand() < 0.25:\n",
    "            tx_df.at[idx,'label'] = 1\n",
    "    \n",
    "    return users, devices, merchants, tx_df\n",
    "\n",
    "users, devices, merchants, tx_df = create_synthetic_graph()\n",
    "tx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5dc2c5",
   "metadata": {},
   "source": [
    "## 2) Build a graph and convert to PyTorch Geometric `Data` object\n",
    "We'll build a bipartite/heterogeneous-style graph by creating nodes for users, devices, merchants and transactions and edges between them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(users, devices, merchants, tx_df):\n",
    "    # create node ids\n",
    "    node_list = users + devices + merchants + tx_df['tx_id'].tolist()\n",
    "    node_index = {n:i for i,n in enumerate(node_list)}\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for n in node_list:\n",
    "        G.add_node(n)\n",
    "    \n",
    "    # edges: user - tx, device - tx, merchant - tx\n",
    "    edges = []\n",
    "    for _, row in tx_df.iterrows():\n",
    "        u = row['user']\n",
    "        d = row['device']\n",
    "        m = row['merchant']\n",
    "        t = row['tx_id']\n",
    "        edges.append((node_index[u], node_index[t]))\n",
    "        edges.append((node_index[d], node_index[t]))\n",
    "        edges.append((node_index[m], node_index[t]))\n",
    "    \n",
    "    # build adjacency list\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # create simple node features: type one-hot and degree\n",
    "    N = len(node_list)\n",
    "    feat_type = np.zeros((N,4), dtype=float)\n",
    "    for i,n in enumerate(node_list):\n",
    "        if n.startswith('U'):\n",
    "            feat_type[i,0]=1.0\n",
    "        elif n.startswith('D'):\n",
    "            feat_type[i,1]=1.0\n",
    "        elif n.startswith('M'):\n",
    "            feat_type[i,2]=1.0\n",
    "        else:\n",
    "            feat_type[i,3]=1.0\n",
    "    degrees = np.array([val for (_,val) in G.degree(node_list)])\n",
    "    degrees = degrees.reshape(-1,1).astype(float)\n",
    "    x = np.hstack([feat_type, degrees])\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    \n",
    "    # labels: only transactions have labels; for other nodes label=-1\n",
    "    y = -1 * torch.ones((N,), dtype=torch.long)\n",
    "    for _, row in tx_df.iterrows():\n",
    "        idx = node_index[row['tx_id']]\n",
    "        y[idx] = int(row['label'])\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    data.node_list = node_list\n",
    "    data.node_index = node_index\n",
    "    return data\n",
    "\n",
    "data = build_graph(users, devices, merchants, tx_df)\n",
    "print('Nodes:', len(data.x))\n",
    "print('Edges:', data.edge_index.shape)\n",
    "# show a few transaction labels\n",
    "for n in tx_df['tx_id'].tolist()[:5]:\n",
    "    print(n, data.y[data.node_index[n]].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3902d51",
   "metadata": {},
   "source": [
    "## 3) Prepare train/test masks for node classification (transactions only)\n",
    "We will create masks that only include transaction nodes for training / validation / test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(data, tx_ids, train_frac=0.7, val_frac=0.15, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tx_indices = [data.node_index[t] for t in tx_ids]\n",
    "    labels = data.y[tx_indices].numpy()\n",
    "    pos_idx = [i for i,lab in zip(tx_indices, labels) if lab==1]\n",
    "    neg_idx = [i for i,lab in zip(tx_indices, labels) if lab==0]\n",
    "    \n",
    "    def split_indices(idxs):\n",
    "        idxs = np.array(idxs)\n",
    "        np.random.shuffle(idxs)\n",
    "        n = len(idxs)\n",
    "        n_train = int(train_frac * n)\n",
    "        n_val = int(val_frac * n)\n",
    "        return idxs[:n_train].tolist(), idxs[n_train:n_train+n_val].tolist(), idxs[n_train+n_val:].tolist()\n",
    "    \n",
    "    pos_train, pos_val, pos_test = split_indices(pos_idx)\n",
    "    neg_train, neg_val, neg_test = split_indices(neg_idx)\n",
    "    \n",
    "    train_idx = pos_train + neg_train\n",
    "    val_idx = pos_val + neg_val\n",
    "    test_idx = pos_test + neg_test\n",
    "    \n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    \n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "train_mask, val_mask, test_mask = create_masks(data, tx_df['tx_id'].tolist())\n",
    "print('Train txn:', train_mask.sum().item(), 'Val txn:', val_mask.sum().item(), 'Test txn:', test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa9ac9",
   "metadata": {},
   "source": [
    "## 4) Define a GNN model (GraphSAGE)\n",
    "We'll define a simple GraphSAGE model for node classification. If torch_geometric isn't available in your environment, install it as shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from torch_geometric.nn import SAGEConv\n",
    "except Exception as e:\n",
    "    print('torch_geometric not available in this environment. The model definition remains visible but will fail if executed without torch-geometric installed.')\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers-2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        if num_layers>1:\n",
    "            self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        else:\n",
    "            self.convs.append(SAGEConv(in_channels, out_channels))\n",
    "        self.lin = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "# instantiate (will fail if SAGEConv is missing)\n",
    "in_ch = data.num_node_features\n",
    "model = GraphSAGE(in_channels=in_ch, hidden_channels=64, out_channels=2, num_layers=3)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8939196",
   "metadata": {},
   "source": [
    "## 5) Training loop\n",
    "We'll train only on transaction nodes (train_mask). Loss computed only for labeled nodes in train mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c05080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "val_mask = val_mask.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # only compute loss on training nodes\n",
    "    loss = F.cross_entropy(out[train_mask], data.y[train_mask].to(torch.long))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(mask):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    probs = F.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "    labels = data.y.cpu().numpy()\n",
    "    mask_idx = mask.cpu().numpy()\n",
    "    if mask_idx.sum() == 0:\n",
    "        return {'auc': None}\n",
    "    auc = roc_auc_score(labels[mask_idx], probs[mask_idx])\n",
    "    preds = (probs[mask_idx] > 0.5).astype(int)\n",
    "    prec = precision_score(labels[mask_idx], preds, zero_division=0)\n",
    "    return {'auc': auc, 'precision': prec}\n",
    "\n",
    "# training loop (small number of epochs for demo)\n",
    "best_val = 0\n",
    "for epoch in range(1, 31):\n",
    "    loss = train_epoch()\n",
    "    val_metrics = evaluate(val_mask)\n",
    "    if val_metrics['auc'] is not None and val_metrics['auc'] > best_val:\n",
    "        best_val = val_metrics['auc']\n",
    "        # save best model\n",
    "        torch.save(model.state_dict(), 'models/gnn_best.pth')\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch:02d} loss={loss:.4f} val_auc={val_metrics[\"auc\"]} val_prec={val_metrics.get(\"precision\")}')\n",
    "\n",
    "# load best and evaluate on test\n",
    "model.load_state_dict(torch.load('models/gnn_best.pth'))\n",
    "print('Test metrics:', evaluate(test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8bdf2",
   "metadata": {},
   "source": [
    "## 6) Visualize a small subgraph and suspicious nodes\n",
    "We'll plot a small neighborhood around a suspicious device or merchant for inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pick a suspicious transaction (label=1)\n",
    "fraud_tx = [n for n in data.node_list if n.startswith('T') and data.y[data.node_index[n]]==1]\n",
    "if len(fraud_tx)>0:\n",
    "    center = fraud_tx[0]\n",
    "    center_idx = data.node_index[center]\n",
    "    # build networkx subgraph of neighbors within 2 hops\n",
    "    edges = [(int(u.item()), int(v.item())) for u,v in data.edge_index.t()]\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    nodes = list(nx.ego_graph(G, center_idx, radius=2).nodes())\n",
    "    sub = G.subgraph(nodes)\n",
    "    pos = nx.spring_layout(sub)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    nx.draw(sub, pos, with_labels=True, node_size=100)\n",
    "    plt.title(f'Neighborhood around {center}')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No fraud transactions found in sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496749c",
   "metadata": {},
   "source": [
    "## Save README and requirements\n",
    "We'll save a README.md and requirements.txt for GitHub upload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = '''# Fraud Detection using Graph Neural Networks (GNN)\n",
    "\n",
    "This repository contains an end-to-end notebook and supporting files for fraud detection using GNNs.\n",
    "\n",
    "Contents:\n",
    "- `notebooks/fraud_gnn.ipynb` - main notebook\n",
    "- `models/` - saved model weights\n",
    "- `data/` - (optional) transaction csv files\n",
    "\n",
    "How to run:\n",
    "1. Install dependencies (torch, torch-geometric, scikit-learn, networkx)\n",
    "2. Open and run the notebook cells in order\n",
    "\n",
    "Notes:\n",
    "- The notebook uses a synthetic dataset for demonstration. Replace with real data for production.\n",
    "- Adjust torch-geometric installation to match your CUDA/PyTorch version.\n",
    "'''\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open('README.md','w') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "reqs = 'pandas\\nnumpy\\nscikit-learn\\ntorch\\ntorch-geometric\\nnetworkx\\nmatplotlib\\npyvis\\njoblib\\n'\n",
    "with open('requirements.txt','w') as f:\n",
    "    f.write(reqs)\n",
    "print('Saved README.md and requirements.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
